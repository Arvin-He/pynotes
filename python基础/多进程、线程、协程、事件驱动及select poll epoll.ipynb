{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多进程、线程、协程、事件驱动及select poll epoll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多线程的使用场景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* IO操作不占用CPU\n",
    "* 计算占用cpu\n",
    "* python多线程不适合cpu密集型任务，适合IO密集型任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多进程 简单的一个多进程例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用于理解对多线程方法的使用: 和线程的方法类似，下面是一个简单的多进程代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def run(name):\n",
    "    time.sleep(2)\n",
    "    print(\"hello\", name)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for i in range(6):\n",
    "        p = multiprocessing.Process(target=run, args=(\"world\",))\n",
    "        p.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python c:/Users/JS-E-PC-10182/Desktop/test01.py\n",
    "hello world\n",
    "hello world\n",
    "hello world\n",
    "hello world\n",
    "hello world\n",
    "hello world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和之前学习的多线程结合在一起使用，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def thread_run():\n",
    "    # 这里表示获取线程id\n",
    "    print(threading.get_ident())  \n",
    "\n",
    "\n",
    "def run(name):\n",
    "    time.sleep(2)\n",
    "    print(\"hello\", name)\n",
    "    t = threading.Thread(target=thread_run)\n",
    "    t.start()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(6):\n",
    "        p = multiprocessing.Process(target=run, args=(\"world\",))\n",
    "        p.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python c:/Users/JS-E-PC-10182/Desktop/test02.py\n",
    "hello world\n",
    "13056\n",
    "hello world\n",
    "16336\n",
    "hello world\n",
    "8800\n",
    "hello world\n",
    "16292\n",
    "hello world\n",
    "14236\n",
    "hello world\n",
    "12576"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着我们查看下面代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import os\n",
    "\n",
    "def info(title):\n",
    "    print(title)\n",
    "    print('module name:', __name__)\n",
    "    print('parent process:', os.getppid())\n",
    "    print('process id:', os.getpid())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    info('main process line:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python c:/Users/JS-E-PC-10182/Desktop/test03.py\n",
    "main process line:\n",
    "module name: __main__\n",
    "parent process: 11156\n",
    "process id: 15536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里要记住：每一个子进程都是由父进程启动的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import os\n",
    "\n",
    "def info(title):\n",
    "    print(title)\n",
    "    print('module name:', __name__)\n",
    "    print('parent process:', os.getppid())\n",
    "    print('process id:', os.getpid())\n",
    "\n",
    "def f(name):\n",
    "    info('called from child process function f:')\n",
    "    print('hello', name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    info('main process line:')\n",
    "    p = Process(target=f, args=('bob',))\n",
    "    p.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python c:/Users/JS-E-PC-10182/Desktop/test03.py\n",
    "main process line:\n",
    "module name: __main__\n",
    "parent process: 11428\n",
    "process id: 3892\n",
    "\n",
    "\n",
    "called from child process function f:\n",
    "module name: __mp_main__\n",
    "parent process: 3892\n",
    "process id: 15652\n",
    "hello bob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进程间数据的交互"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过**Queues**和**Pipe**可以实现进程间数据的**传递**，但是**不能实现数据的共享**,不同进程间内存不是共享的."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用queue实现进程间数据的交互"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "\n",
    "def func():\n",
    "    q.put([22, \"world\", 'hello'])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q = queue.Queue()\n",
    "    t = threading.Thread(target=func)\n",
    "    t.start()\n",
    "    print(q.get(q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python c:/Users/JS-E-PC-10182/Desktop/test04.py\n",
    "[22, 'world', 'hello']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上述代码可以看出线程之间的数据是共享的：父线程可以访问子线程放入的数据\n",
    "\n",
    "如果是多进程之间呢？\n",
    "\n",
    "将代码进行修改如下，让子进程调用父进程数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import queue\n",
    "\n",
    "\n",
    "def f():\n",
    "    q.put([11, None, \"hello\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q = queue.Queue()\n",
    "    p = Process(target=f)\n",
    "    p.start()\n",
    "    print(q.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python c:/Users/JS-E-PC-10182/Desktop/test04.py\n",
    "Process Process-1:\n",
    "Traceback (most recent call last):\n",
    "  File \"C:\\Program Files\\Python36\\lib\\multiprocessing\\process.py\", line 258, in _bootstrap\n",
    "    self.run()\n",
    "  File \"C:\\Program Files\\Python36\\lib\\multiprocessing\\process.py\", line 93, in run\n",
    "    self._target(*self._args, **self._kwargs)\n",
    "  File \"c:\\Users\\JS-E-PC-10182\\Desktop\\test04.py\", line 7,\n",
    "in f\n",
    "    q.put([11, None, \"hello\"])\n",
    "NameError: name 'q' is not defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出: 子进程是**访问不到**父进程的数据\n",
    "\n",
    "我们再次将代码进行修改，写f方法的时候直接将q给线程传入，也就是，只有启动线程，就自动传入线程q,代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import queue\n",
    "\n",
    "\n",
    "def f(data):\n",
    "    data.put([11, None, \"hello\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 切记这里是线程的q\n",
    "    q = queue.Queue()\n",
    "    p = Process(target=f, args=(q,))\n",
    "    p.start()\n",
    "    print(q.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python c:/Users/JS-E-PC-10182/Desktop/test04.py\n",
    "Traceback (most recent call last):\n",
    "  File \"c:/Users/JS-E-PC-10182/Desktop/test04.py\", line 13, in <module>\n",
    "    p.start()\n",
    "  File \"C:\\Program Files\\Python36\\lib\\multiprocessing\\process.py\", line 105, in start\n",
    "    self._popen = self._Popen(self)\n",
    "  File \"C:\\Program Files\\Python36\\lib\\multiprocessing\\context.py\", line 223, in _Popen\n",
    "    return _default_context.get_context().Process._Popen(process_obj)\n",
    "  File \"C:\\Program Files\\Python36\\lib\\multiprocessing\\context.py\", line 322, in _Popen\n",
    "    return Popen(process_obj)\n",
    "  File \"C:\\Program Files\\Python36\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in __init__\n",
    "    reduction.dump(process_obj, to_child)\n",
    "  File \"C:\\Program Files\\Python36\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
    "    ForkingPickler(file, protocol).dump(obj)\n",
    "TypeError: can't pickle _thread.lock objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们需要知道：进程不能访问线程q.\n",
    "\n",
    "所以我们需要改成进程，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "\n",
    "def f(q):\n",
    "    print('222', id(q))\n",
    "    q.put([11, None, \"hello\"])\n",
    "    print('333', id(q))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 这里的q是进程q\n",
    "    q = Queue()\n",
    "    print('111', id(q))\n",
    "    p = Process(target=f, args=(q,))\n",
    "    p.start()\n",
    "    print('444', id(q))\n",
    "    print(q.get())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python c:/Users/JS-E-PC-10182/Desktop/test04.py\n",
    "111 2366118667152\n",
    "444 2366118667152\n",
    "222 2520898670320\n",
    "333 2520898670320\n",
    "[11, None, 'hello']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现在父进程里调用到子进程放入的数据\n",
    "\n",
    "这里需要明白：这里的`q`其实是被克隆了一个`q`，然后将子进程序列化的内容传入的克隆q，然后再反序列化给q,从而实现了进程之间数据的传递"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用pipe进程间数据的交互"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "\n",
    "def f(conn):\n",
    "    print('子进程中pipe id = {}'.format(id(conn)))\n",
    "    print('子进程使用pipe2发送数据')\n",
    "    conn.send([11, None, \"hello from pipe2\"])\n",
    "    conn.send([22, None, \"hello from pipe2\"])\n",
    "    print('子进程接收父进程pipe1发送的数据:', conn.recv())\n",
    "    print('子进程关闭pipe2')\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('创建pipe,返回两个对象分别代表pipe的两端')\n",
    "    pipe1, pipe2 = Pipe()\n",
    "    print('pipe1 id = {}, pipe2 id = {}'.format(id(pipe1), id(pipe2)))\n",
    "    print('创建子进程,并在子进程使用pipe2发送接收数据')\n",
    "    p = Process(target=f, args=(pipe2,))\n",
    "    p.start()\n",
    "    print('父进程接收子进程发送的数据: ', pipe1.recv())\n",
    "    print('父进程接收子进程发送的数据: ', pipe1.recv())\n",
    "    pipe1.send({\"num\": 20, \"data\": None, \"msg\": \"hello from pipe1\"})\n",
    "    print('父进程中pipe id = {}'.format(id(pipe1)))\n",
    "    print('父进程关闭pipe1')\n",
    "    pipe1.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python c:/Users/JS-E-PC-10182/Desktop/test04.py\n",
    "创建pipe,返回两个对象分别代表pipe的两端\n",
    "pipe1 id = 2480042186008, pipe2 id = 2480042185784\n",
    "创建子进程,并在子进程使用pipe2发送接收数据\n",
    "子进程中pipe id = 2841263125560\n",
    "子进程使用pipe2发送数据\n",
    "父进程接收子进程发送的数据:  [11, None, 'hello from pipe2']\n",
    "父进程接收子进程发送的数据:  [22, None, 'hello from pipe2']\n",
    "父进程中pipe id = 2480042186008\n",
    "子进程接收父进程pipe1发送的数据: {'num': 20, 'data': None,\n",
    "'msg': 'hello from pipe1'}\n",
    "父进程关闭pipe1\n",
    "子进程关闭pipe2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码分析：Pipe()会生成两个值，上面的 pipe1 和 pipe2 就如同一条网线的两头，两头都可以发送和接收数据.\n",
    "\n",
    "注意: 子进程的pipe2其实是被克隆了一个pipe2，然后将子进程序列化的内容传入的克隆pipe2，然后再反序列化给pipe2,从而实现了进程之间数据的传递"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过Manager可以不同进程间实现数据的共享"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Manager, Process\n",
    "import os\n",
    "\n",
    "\n",
    "def f(p_index, d, l):\n",
    "    d[1] = \"1\"\n",
    "    d[\"2\"] = 2\n",
    "    d[0.25] = None\n",
    "    l.append({'pid':os.getpid(), 'ppid': os.getppid()})\n",
    "    print('process {}: dict id: {}, list id: {}'.format(p_index, id(d), id(l)))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 这种方式和直接manager=Manager()一样\n",
    "    with Manager() as manager:  \n",
    "        # 生成一个字典，可以在多个进程间共享\n",
    "        d = manager.dict()  \n",
    "        # 生成一个列表，可以在多个进程间共享\n",
    "        l = manager.list()\n",
    "        print('父进程pid = {}'.format(os.getpid()))\n",
    "        print('dict id = {}, list id = {}'.format(id(d), id(l)))\n",
    "        # 存放进程对象列表\n",
    "        p_list = []\n",
    "        # 创建10个进程,并共享数据\n",
    "        for i in range(10):\n",
    "            p = Process(target=f, args=(i, d, l))\n",
    "            p.start()\n",
    "            p_list.append(p)\n",
    "\n",
    "        for res in p_list:\n",
    "            res.join()\n",
    "        print('dict id = {}, list id = {}'.format(id(d), id(l)))\n",
    "        print(d)\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python c:/Users/JS-E-PC-10182/Desktop/test04.py\n",
    "父进程pid = 1376\n",
    "\n",
    "dict id = 1820748326056, list id = 1820748365952\n",
    "process 0: dict id: 3072011621824, list id: 3072014501704\n",
    "process 1: dict id: 2040508143040, list id: 2040510957496\n",
    "process 2: dict id: 1556689671672, list id: 1556692420480\n",
    "process 3: dict id: 1301575914944, list id: 1301578794936\n",
    "process 4: dict id: 1552957920760, list id: 1552960800640\n",
    "process 5: dict id: 2480326989192, list id: 2480329869128\n",
    "process 6: dict id: 3211818063296, list id: 3211820943232\n",
    "process 7: dict id: 2509787846080, list id: 2509790725960\n",
    "process 8: dict id: 1325412079040, list id: 1325414827848\n",
    "process 9: dict id: 1777390015880, list id: 1777392830280\n",
    "dict id = 1820748326056, list id = 1820748365952\n",
    "\n",
    "{1: '1', '2': 2, 0.25: None}\n",
    "[{'pid': 15048, 'ppid': 1376}, {'pid': 7380, 'ppid': 1376}, {'pid': 11872, 'ppid': 1376}, {'pid': 1228, 'ppid': 1376}, {'pid': 7600, 'ppid': 1376}, {'pid': 7628, 'ppid': 1376}, {'pid': 14628, 'ppid': 1376}, {'pid': 4340, 'ppid': 1376}, {'pid': 13568, 'ppid': 1376}, {'pid': 3776, 'ppid': 1376}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过结果可以看出实现了不同进程间数据的共享, 本质上是在父进程创建数据容器, 但不同进程生成数据其实是被克隆的，然后将子进程序列化的内容传入的克隆容器，然后再反序列化给父进程数据容器, 从而实现了进程之间数据的传递"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  进程同步，即进程锁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Lock\n",
    "\n",
    "\n",
    "def f(l, i):\n",
    "    print('this is process {} acquire lock.'.format(i))\n",
    "    l.acquire()\n",
    "    print('this is process {}.'.format(i))\n",
    "    l.release()\n",
    "    print('this is process {} release lock.\\n================'.format(i))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lock = Lock()\n",
    "    for num in range(10):\n",
    "        Process(target=f, args=(lock, num)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python c:/Users/JS-E-PC-10182/Desktop/test04.py\n",
    "this is process 0 acquire lock.\n",
    "this is process 0.\n",
    "this is process 0 release lock.\n",
    "================\n",
    "this is process 1 acquire lock.\n",
    "this is process 1.\n",
    "this is process 1 release lock.\n",
    "================\n",
    "this is process 2 acquire lock.\n",
    "this is process 2.\n",
    "this is process 2 release lock.\n",
    "================\n",
    "this is process 3 acquire lock.\n",
    "this is process 3.\n",
    "this is process 3 release lock.\n",
    "================\n",
    "this is process 6 acquire lock.\n",
    "this is process 6.\n",
    "this is process 6 release lock.\n",
    "================\n",
    "this is process 4 acquire lock.\n",
    "this is process 4.\n",
    "this is process 4 release lock.\n",
    "================\n",
    "this is process 5 acquire lock.\n",
    "this is process 5.\n",
    "this is process 5 release lock.\n",
    "================\n",
    "this is process 7 acquire lock.\n",
    "this is process 7.\n",
    "this is process 7 release lock.\n",
    "================\n",
    "this is process 8 acquire lock.\n",
    "this is process 8.\n",
    "this is process 8 release lock.\n",
    "================\n",
    "this is process 9 acquire lock.\n",
    "this is process 9.\n",
    "this is process 9 release lock.\n",
    "================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可能会觉得这个加锁没有上面作用，其实是这样的，当在屏幕上打印这些内容的时候，**不同进程之间是共享这个屏幕的**，锁的作用在于当一个进程开始打印的时候，其他线程不能打印，从而防止打印乱内容.\n",
    "\n",
    "在windows上可能看不到效果，当不同进程打印的东西比较多的时候，就可以看到打印数据出现乱的情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进程池"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进程池内部维护一个进程序列，当使用时，则去进程池中获取一个进程，如果进程池序列中没有可供使用的进进程，那么程序就会等待，直到进程池中有可用进程为止。\n",
    "\n",
    "\n",
    "进程池中有两个方法：\n",
    "* apply\n",
    "* apply_async（这个就表示异步）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Pool\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "def Foo(i):\n",
    "    time.sleep(1)\n",
    "    print(\"pid = \", os.getpid())\n",
    "    return i + 100\n",
    "\n",
    "\n",
    "def Bar(arg):\n",
    "    print('-->exec done:', arg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = Pool(5)\n",
    "    print('start')\n",
    "    for i in range(10):\n",
    "        pool.apply(func=Foo, args=(i,))\n",
    "#         pool.apply_async(func=Foo, args=(i,))\n",
    "    print('end')\n",
    "    pool.close()\n",
    "    # 进程池中进程执行完毕后再关闭，如果注释，那么程序直接关闭。\n",
    "    pool.join()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python c:/Users/JS-E-PC-10182/Desktop/test04.py\n",
    "start\n",
    "\n",
    "pid =  10848\n",
    "pid =  11520\n",
    "pid =  10612\n",
    "pid =  16120\n",
    "pid =  9008\n",
    "\n",
    "pid =  10848\n",
    "pid =  11520\n",
    "pid =  10612\n",
    "pid =  16120\n",
    "pid =  9008\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从运行结果发现，程序变成了串行了。\n",
    "\n",
    "将上述代码中的：\n",
    "\n",
    "`pool.apply(func=Foo, args=(i,))` 替换为：`pool.apply_async(func=Foo,args=(i,))`, 就解决了之前的的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start\n",
    "end\n",
    "pid =  4829\n",
    "pid =  4830\n",
    "pid =  4831\n",
    "pid =  4833\n",
    "pid =  4832\n",
    "pid =  4829\n",
    "pid =  4831\n",
    "pid =  4833\n",
    "pid =  4830\n",
    "pid =  4832"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多进程之间异步回调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Pool\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "def Foo(i):\n",
    "    time.sleep(1)\n",
    "    print(\"pid = \", os.getpid())\n",
    "    return i + 100\n",
    "\n",
    "\n",
    "def Bar(arg):\n",
    "    print('-->exec done:', arg,  os.getpid())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = Pool(5)\n",
    "    print(os.getpid())\n",
    "    print('start')\n",
    "    for i in range(10):\n",
    "        pool.apply_async(func=Foo, args=(i,), callback=Bar)\n",
    "    print('end')\n",
    "    pool.close()\n",
    "    # 进程池中进程执行完毕后再关闭，如果注释，那么程序直接关闭。\n",
    "    pool.join()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "父进程pid =  16316\n",
    "start\n",
    "end\n",
    "pid =  4954\n",
    "pid =  4957\n",
    "-->exec done: 103 16316\n",
    "-->exec done: 101 16316\n",
    "pid =  4953\n",
    "pid =  4955\n",
    "pid =  4956\n",
    "-->exec done: 102 16316\n",
    "-->exec done: 104 16316\n",
    "-->exec done: 100 16316\n",
    "pid =  4957\n",
    "pid =  4954\n",
    "pid =  4955\n",
    "-->exec done: 105 16316\n",
    "pid =  4956\n",
    "-->exec done: 107 16316\n",
    "-->exec done: 106 16316\n",
    "-->exec done: 108 16316\n",
    "pid =  4953\n",
    "-->exec done: 109 16316"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出回调函数是由父进程/主进程调用."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事件驱动\n",
    "通常，我们写服务器处理模型的程序时，有以下几种模型：\n",
    "\n",
    "（1）每收到一个请求，创建一个新的进程，来处理该请求；\n",
    "\n",
    "（2）每收到一个请求，创建一个新的线程，来处理该请求；\n",
    "\n",
    "（3）每收到一个请求，放入一个事件列表，让主进程通过非阻塞I/O方式来处理请求\n",
    "\n",
    "上面的几种方式，各有千秋，\n",
    "\n",
    "第（1）中方法，由于创建新的进程的开销比较大，所以，会导致服务器性能比较差,但实现比较简单。\n",
    "\n",
    "第（2）种方式，由于要涉及到线程的同步，有可能会面临死锁等问题。\n",
    "\n",
    "第（3）种方式，在写应用程序代码时，逻辑比前面两种都复杂。\n",
    "\n",
    "综合考虑各方面因素，一般普遍认为第（3）种方式是大多数网络服务器采用的方式\n",
    "\n",
    "目前大部分的UI编程都是事件驱动模型，如很多UI平台都会提供onClick()事件，这个事件就代表鼠标按下事件。事件驱动模型大体思路如下：\n",
    "\n",
    "1. 有一个事件（消息）队列；\n",
    "\n",
    "2. 鼠标按下时，往这个队列中增加一个点击事件（消息）；\n",
    "\n",
    "3. 有个循环，不断从队列取出事件，根据不同的事件，调用不同的函数，如onClick()、onKeyDown()等；\n",
    "\n",
    "4. 事件（消息）一般都各自保存各自的处理函数指针，这样，每个消息都有独立的处理函数\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "事件驱动编程是一种编程范式，这里程序的执行流由外部事件来决定。它的特点是包含一个事件循环，当外部事件发生时使用回调机制来触发相应的处理。另外两种常见的编程范式是（单线程）同步以及多线程编程。\n",
    "\n",
    "让我们用例子来比较和对比一下单线程、多线程以及事件驱动编程模型。下图展示了随着时间的推移，这三种模式下程序所做的工作。这个程序有3个任务需要完成，每个任务都在等待I/O操作时阻塞自身。阻塞在I/O操作上所花费的时间已经用灰色框标示出来了。\n",
    "\n",
    "\n",
    "\n",
    "在单线程同步模型中，任务按照顺序执行。如果某个任务因为I/O而阻塞，其他所有的任务都必须等待，直到它完成之后它们才能依次执行。这种明确的执行顺序和串行化处理的行为是很容易推断得出的。如果任务之间并没有互相依赖的关系，但仍然需要互相等待的话这就使得程序不必要的降低了运行速度。\n",
    "\n",
    " \n",
    "\n",
    "在多线程版本中，这3个任务分别在独立的线程中执行。这些线程由操作系统来管理，在多处理器系统上可以并行处理，或者在单处理器系统上交错执行。这使得当某个线程阻塞在某个资源的同时其他线程得以继续执行。与完成类似功能的同步程序相比，这种方式更有效率，但程序员必须写代码来保护共享资源，防止其被多个线程同时访问。多线程程序更加难以推断，因为这类程序不得不通过线程同步机制如锁、可重入函数、线程局部存储或者其他机制来处理线程安全问题，如果实现不当就会导致出现微妙且令人痛不欲生的bug。\n",
    "\n",
    " \n",
    "\n",
    "在事件驱动版本的程序中，3个任务交错执行，但仍然在一个单独的线程控制中。当处理I/O或者其他昂贵的操作时，注册一个回调到事件循环中，然后当I/O操作完成时继续执行。回调描述了该如何处理某个事件。事件循环轮询所有的事件，当事件到来时将它们分配给等待处理事件的回调函数。这种方式让程序尽可能的得以执行而不需要用到额外的线程。事件驱动型程序比多线程程序更容易推断出行为，因为程序员不需要关心线程安全问题。\n",
    "\n",
    "当我们面对如下的环境时，事件驱动模型通常是一个好的选择：\n",
    "\n",
    " \n",
    "\n",
    "（1）程序中有许多任务\n",
    "\n",
    "（2）任务之间高度独立（因此它们不需要互相通信，或者等待彼此）\n",
    "\n",
    "（3）在等待事件到来时，某些任务会阻塞。\n",
    "\n",
    "当应用程序需要在任务间共享可变的数据时，这也是一个不错的选择，因为这里不需要采用同步处理。\n",
    "\n",
    "网络应用程序通常都有上述这些特点，这使得它们能够很好的契合事件驱动编程模型。\n",
    "\n",
    "IO多路复用\n",
    "用户空间和内核空间\n",
    "操作系统都是采用虚拟存储器，对于32位操作系统，它的寻址空间（虚拟存储空间）为4G。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护内存空间，也有访问底层硬件设备的所有权限，为了保证用户进程不能直接操作内核，保证内核的安全，操作系统将虚拟空间分为两部分：一部分为内核空间，一部分是用户空间，针对linux系统而言，将最高的1G字节给内核使用，称为内核空间，将3G字节的供各个进程使用，称为用户空间\n",
    "\n",
    "文件描述符fd\n",
    "文件描述符是一个用于表述指向文件的引用的抽象化概念\n",
    "\n",
    "文件描述符在形式上是一个非负整数，实际上，它是一个索引值，指内核为每一个进程所维护的进程打开文件的记录的记录表，当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。\n",
    "\n",
    "缓存IO\n",
    "缓存IO，也被称为标准IO，大多数文件系统默认IO操作都是缓存IO，在Linux的缓存IO机制中，操作系统会将IO的数据缓存在文件系统的页缓存（page cache）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间\n",
    "\n",
    "缓存IO的缺点：\n",
    "\n",
    "数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的CPU以及内存开销是非常大的\n",
    "\n",
    "IO模式\n",
    "对于一次IO访问（以read为例子），数据会先拷贝到操作系统内核的缓冲区中，然后会从操作系统内核的缓冲区拷贝到应用程序的地址空间，也就是说当一个read操作发生时，它会经历两个阶段：\n",
    "\n",
    "1. 等待数据准备\n",
    "\n",
    "2. 经数据从内核拷贝到进程\n",
    "\n",
    "正是因为这两个阶段，linux系统产生了五种网络模式的方案\n",
    "\n",
    "1. 阻塞I/O（blocking IO）\n",
    "\n",
    "2. 非阻塞I/O（nonblocking IO）\n",
    "\n",
    "3. I/O多路复用（IO multiplexing）\n",
    "\n",
    "4. 信号驱动I/O（signal driven IO）\n",
    "\n",
    "5. 异步I/O（asynchromous IO）\n",
    "\n",
    "注意：信号驱动I/O（signal driven IO）在实际中不常用\n",
    "\n",
    "阻塞I/O（blocking IO）\n",
    "在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：\n",
    "\n",
    "\n",
    "\n",
    "当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。\n",
    "\n",
    " \n",
    "\n",
    "所以，blocking IO的特点就是在IO执行的两个阶段都被block了\n",
    "\n",
    "非阻塞I/O\n",
    "linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：\n",
    "\n",
    "\n",
    "\n",
    "当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。\n",
    "\n",
    " \n",
    "\n",
    "所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。\n",
    "\n",
    "I/O多路复用（IO multiplexing）\n",
    "IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。\n",
    "\n",
    " \n",
    "\n",
    "所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。\n",
    "\n",
    " \n",
    "\n",
    "这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。\n",
    "\n",
    " \n",
    "\n",
    "所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）\n",
    "\n",
    " \n",
    "\n",
    "在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。\n",
    "\n",
    "异步I/O（asynchronous IO）\n",
    "Linux下的asynchronous IO其实用得很少。先看一下它的流程：\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。\n",
    "\n",
    "关于select poll epoll\n",
    "select\n",
    "sekect是通过一个select（）系统调用来监视多个文件描述符，当select()返回后，该数组中就绪的文件描述符便会被该内核修改标志位，使得进程可以获得这些文件描述符从而进行后续的读写操作\n",
    "\n",
    "select的优点就是支持跨平台\n",
    "\n",
    "缺点在于单个进程能够监视的文件描述符的数量存在最大限制\n",
    "\n",
    "另外select()所维护的存储大量文件描述符的数据结构，随着文件描述符数量的增大，其复制的开销也线性增长。同时，由于网络响应时间的延迟使得大量TCP连接处于非活跃状态，但调用select()会对所有socket进行一次线性扫描，所以这也浪费了一定的开销。\n",
    "\n",
    "poll\n",
    "和select在本质上没有多大差别，但是poll没有最大文件描述符数量的限制\n",
    "\n",
    "poll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。\n",
    "\n",
    "另外，select()和poll()将就绪的文件描述符告诉进程后，如果进程没有对其进行IO操作，那么下次调用select()和poll()的时候将再次报告这些文件描述符，所以它们一般不会丢失就绪的消息，这种方式称为水平触发（Level Triggered）。\n",
    "\n",
    " \n",
    "\n",
    "epoll\n",
    "epoll可以同时支持水平触发和边缘触发（Edge Triggered，只告诉进程哪些文件描述符刚刚变为就绪状态，它只说一遍，如果我们没有采取行动，那么它将不会再次告知，这种方式称为边缘触发），理论上边缘触发的性能要更高一些，但是代码实现相当复杂。\n",
    "\n",
    " \n",
    "\n",
    "epoll同样只告知那些就绪的文件描述符，而且当我们调用epoll_wait()获得就绪文件描述符时，返回的不是实际的描述符，而是一个代表就绪描述符数量的值，你只需要去epoll指定的一个数组中依次取得相应数量的文件描述符即可，这里也使用了内存映射（mmap）技术，这样便彻底省掉了这些文件描述符在系统调用时复制的开销。\n",
    "\n",
    " \n",
    "\n",
    "另一个本质的改进在于epoll采用基于事件的就绪通知方式。在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知\n",
    "\n",
    " \n",
    "\n",
    "以select方法为例子进行理解\n",
    "Python的select()方法直接调用操作系统的IO接口，它监控sockets,open files, and pipes(所有带fileno()方法的文件句柄)何时变成readable 和writeable, 或者通信错误，select()使得同时监控多个连接变的简单，并且这比写一个长循环来等待和监控多客户端连接要高效，因为select直接通过操作系统提供的C的网络接口进行操作，而不是通过Python的解释器。\n",
    "\n",
    "接下来通过echo server例子要以了解select 是如何通过单进程实现同时处理多个非阻塞的socket连接的\n",
    "\n",
    "代码如下：\n",
    "\n",
    "复制代码\n",
    " 1 #AUTHOR:FAN\n",
    " 2 \n",
    " 3 import select\n",
    " 4 import socket\n",
    " 5 import queue\n",
    " 6 server = socket.socket()\n",
    " 7 server.bind(('127.0.0.1',9999))\n",
    " 8 server.listen()\n",
    " 9 \n",
    "10 server.setblocking(False)#不阻塞\n",
    "11 msg_dict = {}\n",
    "12 inputs=[server,]\n",
    "13 outputs=[]\n",
    "14 \n",
    "15 while True:\n",
    "16     readable, writeable, exceptional = select.select(inputs, outputs, inputs)\n",
    "17     print(readable, writeable, exceptional)\n",
    "18     for r in readable:\n",
    "19         if r is server:   #代表来了一个新连接\n",
    "20             conn,addr = server.accept()\n",
    "21             print(\"来了一个新连接：\",addr)\n",
    "22             inputs.append(conn)  #是因为这个新建立的连接还没发数据过来，现在就接收的话程序就报错了\n",
    "23             #所以要想要实现这个客户端发数据来时server端能知道，就需要让select再监测这个conn\n",
    "24             msg_dict[conn] = queue.Queue() #初始化一个队列，后面需要返回给这个客户端的数据\n",
    "25         else:\n",
    "26             data = r.recv(1024)\n",
    "27             print(\"收到数据：\",data)\n",
    "28             msg_dict[r].put(data)\n",
    "29             outputs.append(r)  #放入返回的连接队列里\n",
    "30 \n",
    "31     for w in writeable:    #要返回给客户端的连接列表\n",
    "32         data_to_client = msg_dict[w].get()\n",
    "33         w.send(data_to_client)  #返回给客户端源数据\n",
    "34         outputs.remove(w)   #确保下次循环的时候writeable，不能返回这个已经处理完的连接了\n",
    "35     for e in exceptional:\n",
    "36         if e in outputs:\n",
    "37             outputs.remove(e)\n",
    "38         inputs.remove(e)\n",
    "39         del msg_dict[e]\n",
    "复制代码\n",
    "其实上述的代码相对来说是比较麻烦，python已经封装了selectors模块，并且这个模块中包含了select和epoll,会根据系统自动识别（windows只支持select,linux是二者都支持），默认用epoll\n",
    "\n",
    "如果将上述代码用selectors模块的方式写，代码如下：\n",
    "\n",
    " \n",
    "\n",
    "复制代码\n",
    " 1 #AUTHOR:FAN\n",
    " 2 \n",
    " 3 \n",
    " 4 import selectors\n",
    " 5 import socket\n",
    " 6 \n",
    " 7 sel = selectors.DefaultSelector()\n",
    " 8 def accept(server,mask):\n",
    " 9     conn,addr = server.accept()\n",
    "10     print(\"一个新的连接\",addr)\n",
    "11     print(conn)\n",
    "12     conn.setblocking(False)\n",
    "13     sel.register(conn,selectors.EVENT_READ,read)  #新连接注册read回调函数\n",
    "14     print(\"done\")\n",
    "15 \n",
    "16 def read(conn,mask):\n",
    "17     print(\"ccc\")\n",
    "18     print(\"mask:\",mask)\n",
    "19     data = conn.recv(1024)\n",
    "20     if data:\n",
    "21         print(data)\n",
    "22         conn.send(data)\n",
    "23     else:\n",
    "24         print(\"客户端断开连接\")\n",
    "25         sel.unregister(conn)\n",
    "26         conn.close()\n",
    "27 \n",
    "28 server = socket.socket()\n",
    "29 server.bind(('127.0.0.1',9999))\n",
    "30 server.listen()\n",
    "31 server.setblocking(False)\n",
    "32 sel.register(server,selectors.EVENT_READ,accept)\n",
    "33 \n",
    "34 while True:\n",
    "35     print(\"cccccccsssssss\")\n",
    "36     events = sel.select() #默认阻塞，有活动连接，有活动连接就返回活动的连接列表\n",
    "37     print(events)\n",
    "38     for key,mask in events:\n",
    "39         print(\"key:%s    mask:%s\"%(key,mask))\n",
    "40         callback = key.data  #这里就是回调函数及上述的accept\n",
    "41         print(\"key.data:\",key.data)\n",
    "42         print(\"key.fileobj:\",key.fileobj)\n",
    "43         callback(key.fileobj,mask) #key.fileobj\n",
    "复制代码\n",
    " \n",
    "\n",
    "我们用客户端模拟同时并发一万去连接服务端\n",
    "\n",
    "客户端代码如下：\n",
    "\n",
    "复制代码\n",
    " 1 #AUTHOR:FAN\n",
    " 2 \n",
    " 3 \n",
    " 4 import socket\n",
    " 5 import sys\n",
    " 6 \n",
    " 7 messages = [ b'This is the message. ',\n",
    " 8              b'It will be sent ',\n",
    " 9              b'in parts.',\n",
    "10              ]\n",
    "11 server_address = ('192.168.8.102', 10000)\n",
    "12 socks = [ socket.socket(socket.AF_INET, socket.SOCK_STREAM) for i in range(10000)\n",
    "13           ]\n",
    "14 print('connecting to %s port %s' % server_address)\n",
    "15 for s in socks:\n",
    "16     s.connect(server_address)\n",
    "17 \n",
    "18 for message in messages:\n",
    "19     for s in socks:\n",
    "20         print('%s: sending \"%s\"' % (s.getsockname(), message) )\n",
    "21         s.send(message)\n",
    "22     for s in socks:\n",
    "23         data = s.recv(1024)\n",
    "24         print( '%s: received \"%s\"' % (s.getsockname(), data) )\n",
    "25         if not data:\n",
    "26             print(sys.stderr, 'closing socket', s.getsockname() )\n",
    "复制代码\n",
    "将服务端放到linux服务端，在本机执行客户端，从而实现了上万的并发\n",
    "\n",
    "\n",
    "http://www.cnblogs.com/zhaof/p/5932461.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
