{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrapy分布式原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapy单机架构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单机架构是在本机维护一个爬取队列，Scheduler进行调度\n",
    "\n",
    "实现多台服务器共同爬取数据关键就是: **共享爬取队列**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分布式架构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/15.png)\n",
    "\n",
    "或\n",
    "\n",
    "![](images/16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何维护共享队列?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般通过Redis为维护，理由如下:\n",
    "\n",
    "1. Redis，非关系型数据库，Key-Value形式存储，结构灵活。\n",
    "2. redis是内存中的数据结构存储系统，处理速度快，提供队列集合等多种存储结构，方便队列维护."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何去重？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "借助redis的集合，redis提供集合数据结构，在redis集合中存储每个request的指纹,比如: url或url的MD5值\n",
    "\n",
    "在向request队列中加入Request前先验证这个Request的指纹是否已经加入集合中。\n",
    "\n",
    "如果已经存在则不添加到request队列中，如果不存在，则将request加入到队列并将指纹加入集合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何防止中断？如果某个slave因为特殊原因宕机，如何解决？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里是做启动判断，在每台slave的Scrapy**启动的时候**都会判断当前redis request队列是否为空\n",
    "\n",
    "如果不为空，则从队列中获取下一个request执行爬取。\n",
    "\n",
    "如果为空则重新开始爬取，第一台丛集执行爬取向队列中添加request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何实现上述这种架构？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有一个scrapy-redis的库，提供了上述的这些功能\n",
    "\n",
    "scrapy-redis改写了Scrapy的调度器，队列等组件，利用他可以方便的实现Scrapy分布式架构\n",
    "\n",
    "[scrapy-redis的地址：](https://github.com/rmax/scrapy-redis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建分布式爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[参考官网地址：](https://scrapy-redis.readthedocs.io/en/stable/)\n",
    "\n",
    "#### 修改该settings中的配置信息：\n",
    "替换scrapy调度器\n",
    "\n",
    "`SCHEDULER = \"scrapy_redis.scheduler.Scheduler\"`\n",
    "\n",
    "#### 添加去重的class\n",
    "`DUPEFILTER_CLASS = \"scrapy_redis.dupefilter.RFPDupeFilter\"`\n",
    "\n",
    "#### 添加pipeline\n",
    "如果添加这行配置，每次爬取的数据也都会入到redis数据库中，所以一般这里不做这个配置\n",
    "```\n",
    "ITEM_PIPELINES = {\n",
    "'scrapy_redis.pipelines.RedisPipeline': 300\n",
    "}\n",
    "```\n",
    "\n",
    "#### 共享的爬取队列，这里用需要redis的连接信息\n",
    "这里的user:pass表示用户名和密码，如果没有则为空就可以\n",
    "`REDIS_URL = 'redis://user:pass@hostname:9001'`\n",
    "\n",
    "设置为为True则不会清空redis里的dupefilter和requests队列\n",
    "这样设置后指纹和请求队列则会一直保存在redis数据库中，默认为False，一般不进行设置\n",
    "\n",
    "`SCHEDULER_PERSIST = True`\n",
    "\n",
    "#### 设置重启爬虫时是否清空爬取队列\n",
    "这样每次重启爬虫都会清空指纹和请求队列,一般设置为False\n",
    "`SCHEDULER_FLUSH_ON_START=True`\n",
    "\n",
    "### 分布式\n",
    "将上述更改后的代码拷贝的各个服务器，当然关于数据库这里可以在每个服务器上都安装数据，也可以共用一个数据，当然各个服务器上也不能忘记：\n",
    "所有的服务器都要安装`scrapy,scrapy_redis,pymongo`\n",
    "\n",
    "这样运行各个爬虫程序启动后，在redis数据库就可以看到如下内容，dupefilter是指纹队列，requests是请求队列"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
