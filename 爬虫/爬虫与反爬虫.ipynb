{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬虫与反爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 爬虫中的一些概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 爬虫:自动获取网站数据的程序\n",
    "* 反爬虫：使用技术手段防止爬虫程序爬取数据\n",
    "* 误伤：反爬虫技术将普通用户识别为爬虫，这种情况多出现在封ip中，例如学校网络、小区网络再或者网络网络都是共享一个公共ip，这个时候如果是封ip就会导致很多正常访问的用户也无法获取到数据。所以相对来说封ip的策略不是特别好，通常都是禁止某ip一段时间访问。\n",
    "* 拦截：成功拦截爬虫，一般拦截率越高，误伤率也就越高\n",
    "* 成本：反爬虫也是需要人力和机器成本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 反爬虫目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 初学者写的爬虫：简单粗暴，不管对端服务器的压力，甚至会把网站爬挂掉了\n",
    "* 数据保护：很多的数据对某些公司网站来说是比较重要的不希望被别人爬取\n",
    "* 商业竞争问题：举个关于京东和天猫例子，假如京东内部通过程序爬取天猫所有的商品信息，从而做对应策略这样对天猫来说就造成了非常大的竞争"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 爬虫与反爬虫对抗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 反什么样的低级爬虫?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 简单粗暴的爬虫\n",
    "    这样的爬虫通常是新手所写,简单暴力,根本不管服务器压力，而且人数不可预测，很容易把网站弄挂。\n",
    "2. 失控的僵尸爬虫\n",
    "    托管在某些服务器上的小爬虫，已经无人认领了，但依然在辛勤地工作着。但是这些爬虫爬不到任何数据，除了http code是200以外，一切都是不对的，错误的数据.有点蜜罐的感觉."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何编写高级爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 分布式\n",
    "    通常会有一些教材告诉你，为了爬取效率，需要把爬虫分布式部署到多台机器上。这完全是骗人的。分布式唯一的作用是：防止对方封IP。封IP是终极手段，效果非常好，当然，误伤起用户也是非常爽的。\n",
    "    \n",
    "2. 模拟JavaScript\n",
    "    有些教程会说，模拟javascript，抓取动态网页，是进阶技巧。但是其实这只是个很简单的功能。因为，如果对方没有反爬虫，你完全可以直接抓ajax本身，而无需关心js怎么处理的。如果对方有反爬虫，那么javascript必然十分复杂，重点在于分析，而不仅仅是简单的模拟。\n",
    "    \n",
    "3. PhantomJs\n",
    "    这个东西本意是用来做自动测试的，结果因为效果很好，很多人拿来做爬虫。但是这个东西有个硬伤，就是：效率。此外PhantomJs也是可以被抓到的."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 爬与反爬权衡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "越是低级的爬虫，越容易被封锁，但是性能好，成本低。越是高级的爬虫，越难被封锁，但是性能低，成本也越高。\n",
    "\n",
    "当成本高到一定程度，我们就可以无需再对爬虫进行封锁。经济学上有个词叫边际效应。付出成本高到一定程度，收益就不是很多了。\n",
    "\n",
    "如果对双方资源进行对比，发现无条件跟对方死磕，是不划算的。应该有个平衡点，超过这个点，就让它爬好了。反爬虫不是为了面子，而是为了商业因素。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 反爬手段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 后台对请求进行统计，如果单个IP访问超过阈值，予以封锁。\n",
    "    这个效果还不错，但是有 2 个缺陷:\n",
    "    * 非常容易误伤普通用户\n",
    "    * IP不值钱，几十块钱甚至有可能买到几十万个IP\n",
    "2. 后台对请求进行统计，如果单个session访问超过阈值，予以封锁。    \n",
    "    这个其实效果更差，因为session完全不值钱，重新申请一个就可以了。\n",
    "3. 后台对请求进行统计，如果单个userAgent访问超过阈值，予以封锁。    \n",
    "    这个是大招，类似于抗生素之类的，效果出奇的好，但杀伤力过大，误伤非常严重，使用的时候要非常小心。至今为止也就短暂封杀过mac下的火狐。\n",
    "4. 以上的组合\n",
    "    组合起来能力变大，误伤率下降，在遇到低级爬虫的时候，还是比较好用的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 反爬虫检测到爬虫后的措施是?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 直接拦截. 应对措施: 换IP或user-agent\n",
    "2. 正常返回数据,但是给假数据,(也就是投毒). 应对措施: 校验数据,并及时关闭爬虫.\n",
    "3. 连接服务器正常,但服务器是一直不给响应,导致处在客户端的爬虫在一直等待响应,爬虫进程始终不结束. 应对措施: 请求设置超时"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
