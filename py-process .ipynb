{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# py-process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''python实现多进程有2种方式:\n",
    "1. os.fork()方法, 仅适用unix/linux系统, 不支持windows\n",
    "2. multiprocessing模块, 跨平台\n",
    "'''\n",
    "\n",
    "'''说明: 调用fork函数返回2次, 因为操作系统要将父进程复制一个子进程, 这2个进程几乎完全相同, \n",
    "fork方法分别要在父进程和子进程中返回, 子进程永远返回0, 父进程返回子进程的pid\n",
    "'''\n",
    "# 使用fork方法创建进程\n",
    "import os\n",
    "print(\"current pid = {}\".format(os.getpid()))\n",
    "pid = os.fork()\n",
    "if pid < 0:\n",
    "    print(\"error in fork\")\n",
    "elif pid == 0:\n",
    "    print(\"this is child process = {}, my parent process id = {}\".format(\n",
    "        os.getpid(), os.getppid()))\n",
    "else:\n",
    "    print(\"i {} created a child process {}\".format(os.getpid(), pid))\n",
    "\n",
    "# 使用multiprocess模块创建多进程\n",
    "'''创建子进程只需要传入一个执行函数和函数的参数,就完成一个process实例的创建,\n",
    "用start()方法启动进程,用join()方法实现进程间同步\n",
    "如果在创建Process时不指定target，那么执行时没有任何效果。因为默认的run方法是判断如果不指定target，那就什么都不做\n",
    "join方法的作用:阻塞当前进程，直到调用join方法的那个进程执行完，再继续执行当前进程。\n",
    "使用多进程的常规方法是，先依次调用start启动进程，再依次调用join要求主进程等待子进程的结束。\n",
    " '''\n",
    "import os\n",
    "from multiprocessing import Process\n",
    "\n",
    "\n",
    "def run_proc(name):\n",
    "    print(\"child process {} {} is running...\".format(name, os.getpid()))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"parent process is {}\".format(os.getpid()))\n",
    "    for i in range(5):\n",
    "        p = Process(target=run_proc, args=(str(i),))\n",
    "        print(\"process will start.\")\n",
    "        p.start()\n",
    "    p.join()\n",
    "    print(\"process end.\")\n",
    "\n",
    "\n",
    "# 进程池\n",
    "# 如果要启动大量子进程,则使用进程池比较合适,默认进程池大小是cpu的核数\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "def run_task(name):\n",
    "    print(\"task {} (pid = {}) is running...\".format(name, os.getpid()))\n",
    "    time.sleep(random.random() * 3)\n",
    "    print(\"task {} is end\".format(name))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"current process pid = {}\".format(os.getpid()))\n",
    "    p = Pool(processes=3)\n",
    "    for i in range(5):\n",
    "        p.apply_async(run_task, args=(i, ))\n",
    "    print(\"waiting for all subprocesses done...\")\n",
    "    p.close()\n",
    "    # 注意: 调用join之前，先调用close函数，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束\n",
    "    p.join()\n",
    "    print(\"all subprocess done\")\n",
    "\n",
    "# 函数解释：\n",
    "# apply_async(func[, args[, kwds[, callback]]]) 它是非阻塞，\n",
    "# apply(func[, args[, kwds]])是阻塞的\n",
    "# close()    关闭pool，使其不在接受新的任务。\n",
    "# terminate()    结束工作进程，不在处理未完成的任务。\n",
    "# join()    主进程阻塞，等待子进程的退出， join方法要在close或terminate之后使用。\n",
    "\n",
    "\n",
    "# 使用pool.map函数\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def run_task(x):\n",
    "    print(x * x)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = multiprocessing.Pool(multiprocessing.cpu_count())\n",
    "    i_list = range(8)\n",
    "    pool.map(run_task, i_list)\n",
    "\n",
    "# 进程间通信,主要使用Queue和Pipe两种方式\n",
    "# Pipe主要用于2个进程间的通信\n",
    "# Queue主要用于多个进程间的通信\n",
    "\n",
    "'''Queue通信方式:\n",
    "Put方法:将数据插入到队列中,该方法有2个可选参数:blocked和timeout.\n",
    "blocked为true,且timeout为正值,则阻塞timeout指定的时间,知道队列有剩余空间,若超时则抛出Queue.Full异常.\n",
    "blocked为false,若队列已满,则立刻抛出Queue.Full异常\n",
    "Get方法:从队列读取并删除一个元素,该方法有2个可选参数:blocked和timeout.\n",
    "blocked为true,且timeout为正值,若在timeout指定的等待时间内没有取到元素,则抛出Queue.Empty异常\n",
    "blocked为false,若queue有一个值可用,则立即返回该值,若queue为空,则立即抛出Queue.Empty异常\n",
    "'''\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "import os, time, random\n",
    "\n",
    "def proc_write(q, urls):\n",
    "    print(\"process {} is writing...\".format(os.getpid()))\n",
    "    for url in urls:\n",
    "        q.put(url)\n",
    "        print(\"put {} to queue...\".format(url))\n",
    "        time.sleep(random.random())\n",
    "\n",
    "def proc_read(q):\n",
    "    print(\"process {} is reading...\".format(os.getpid()))\n",
    "    while True:\n",
    "        url = q.get(True)\n",
    "        print(\"get {} from queue\".format(url))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q = Queue()\n",
    "    proc_write1 = Process(target=proc_write, args=(q, ['url_1', 'url_2', 'url_3']))\n",
    "    proc_write2 = Process(target=proc_write, args=(q, ['url_4', 'url_5', 'url_6']))\n",
    "\n",
    "    proc_reader = Process(target=proc_read, args=(q, ))\n",
    "\n",
    "    proc_write1.start()\n",
    "    proc_write2.start()\n",
    "\n",
    "    proc_reader.start()\n",
    "\n",
    "    proc_write1.join()\n",
    "    proc_write2.join()\n",
    "    # proc_reader进程是死循环,无法等待其结束,所以不能使用join, 只能强行终止\n",
    "    proc_reader.terminate()\n",
    "    \n",
    "\n",
    "# pipe通信机制\n",
    "# pipe常用来在两个进程间进行通信,分别位于管道的两端,Pipe方法返回(conn1, conn2),代表管道的两个端, Pipe方法有duplex参数,默认为true,即全双工模式\n",
    "# duplex为true,则这个管道是全双工,即conn1和conn2均可收发.全双工模式下,调用conn1.send发送消息,conn1.recv接收消息,若没有消息可接收,recv方法会一直阻塞,\n",
    "# 若管道被关闭,则conn1.recv方法会抛出EOFError\n",
    "# duplex为false,则conn1只负责接收消息,conn2只负责发送消息\n",
    "import multiprocessing\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "def proc_send(pipe, urls):\n",
    "    for url in urls:\n",
    "        print(\"process {} send {}\".format(os.getpid(), url))\n",
    "        pipe.send(url)\n",
    "        time.sleep(random.random())\n",
    "\n",
    "\n",
    "def proc_recv(pipe):\n",
    "    while True:\n",
    "        print(\"process {} recev {}\".format(os.getpid(), pipe.recv()))\n",
    "        time.sleep(random.random())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pipe = multiprocessing.Pipe()\n",
    "    p1 = multiprocessing.Process(target=proc_send, args=(\n",
    "        pipe[0], ['url_' + str(i) for i in range(10)]))\n",
    "    p2 = multiprocessing.Process(target=proc_recv, args=(pipe[1], ))\n",
    "\n",
    "    p1.start()\n",
    "\n",
    "    p2.start()\n",
    "\n",
    "    p1.join()\n",
    "    # p2.join()\n",
    "    p2.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
